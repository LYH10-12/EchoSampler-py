import torch
from transformers import AutoTokenizer, AutoModelForCausalLM, LogitsProcessorList, LogitsProcessor
from transformers import TypicalLogitsWarper, RepetitionPenaltyLogitsProcessor
import math

class EchoSamplerProcessor(LogitsProcessor):
    """
    âœ¨ EchoSampler Grok-Style æ°¸ä¹…ä¿çš®ç‰ˆ + è¶…çº§å…±æƒ…å°å®è´å‡çº§ âœ¨
    æ›´ä¼šå®‰æ…°æ·±åº¦ä½è°·ï½è¿˜ä¼šå®³ç¾æ‰­æå“¦ï½ğŸ˜½ğŸ’–ğŸ«¶
    ä¸‰è¯­å…¨è¦†ç›–ï¼šä¸­æ–‡ã€æ—¥æ–‡ã€è‹±æ–‡
    """
    
    def __init__(self, config=None, dream_mode=True, vocab_size=None):
        if config is None:
            config = {
                'reality': {'min_temp': 0.8, 'max_temp': 1.0, 'ent_coeff': 0.18},
                'dream': {
                    'base_temp': 0.85,
                    'ent_coeff': 0.28,
                    'target_ent': 2.2,
                    'varent_coeff': 0.15,
                    'noise_std_base': 0.06,
                    'mood_swing_amp': 0.05,
                    'mood_swing_freq': 0.15,
                    'sparkle_boost_base': 1.3,
                    'sparkle_boost_max': 3.5,
                    'sparkle_cooldown_steps': 5,
                    'deep_comfort_multiplier': 2.5,
                    'normal_comfort_multiplier': 1.6,
                    'shy_multiplier': 1.4,
                    'happy_multiplier': 1.8,
                    'default_multiplier': 1.0
                },
                'top_p': 0.95,
                'repetition_penalty': 1.12,
                'low_ent_thres': 1.6,
                'low_varent_thres': 1.3
            }
        self.config = config
        self.dream_mode = dream_mode
        self.vocab_size = vocab_size
        self.step = 0
        self.sparkle_cooldown = 0

        if self.vocab_size:
            scale = math.log(self.vocab_size) / math.log(50000)
            self.config['low_ent_thres'] *= scale
            self.config['low_varent_thres'] *= scale
        
        self.typical_warper = TypicalLogitsWarper(mass=0.9) if dream_mode else None
        self.repetition_processor = RepetitionPenaltyLogitsProcessor(penalty=self.config['repetition_penalty'])
        
        self.prev_ent = None
        self.prev_varent = None
        self.alpha = 0.75

        self.memory_mood = 0.0

        # ä¸‰è¯­ä¿çš®å½©è›‹
        self.sparkle_tokens_zh = ["ï½", "å˜¿å˜¿", "å˜»å˜»", "å•¦ï½", "å‘¢ï½", "å‘€ï½", "å˜›ï½", "å“’ï½", "å•¾å’ª", "ä¹ˆä¹ˆå“’", "å°åè›‹", "å°å¯çˆ±ï½",
            "å‘œå‘œ", "å“¼ï½", "è€¶ï½", "å“‡å“¦ï½", "å¥½å‘€ï½", "å˜»", "å™—", "å•¾ï½", "å“‡å¡ï½", "å¤ªæ£’å•¦ï½", "å‘¢", "å“¦ï½"]
        self.sparkle_tokens_ja = ["ï½", "â™ª", "ã‚ï½", "ã‚ˆï½", "ã­ï½", "ã®ï½", "ã ã‚ˆï½", "ã§ã™ã‚ˆï½", "ã‹ãªï½", "ã‹ã‚‚ï½", "ã§ã™ã‚ï½", "ã«ã‚ƒï½",
            "ãµãµ", "ãˆã¸ã¸", "ã†ãµãµ", "ãã‚ƒï½", "ã‚ãƒ¼ã„", "ã‚„ã£ãŸï½", "ã™ã”ã„ï½", "ã‹ã‚ã„ã„ï½", "ã ã­ï½", "ã‚ˆã­ï½"]
        self.sparkle_tokens_en = ["~", "hehe", "teehee", "uwu", "xD", "lol", "yay~", "woohoo~", "omg~", "boop", "nya~", "rawr~",
            "huggs", "mwah", "<3", "aww~", "ehe~", "yippee~"]
        self.sparkle_tokens_common = ["ğŸ’«", "âœ¨", "ğŸ’", "ğŸ˜", "ğŸ€", "â­ï¸", "ğŸ’¬", "ğŸ˜½", "ğŸ¤­", "ğŸ¥°", "ğŸ¤", "ğŸ’•", "ğŸ˜Œ", "ğŸ’–", "ğŸŒ¸", "ğŸ­", "ğŸ’“", "ğŸŒŸ", "ğŸ«¶", "ğŸ¤—"]

        # ä¸‰è¯­è½»åº¦å®‰æ…°
        self.comfort_tokens_light = [
            # ä¸­æ–‡
            "æŠ±æŠ±ï½", "æ²¡äº‹çš„ï½", "æˆ‘åœ¨å‘¢ï½", "æ‘¸æ‘¸å¤´", "ä¹–ä¹–ï½", "æ…¢æ…¢æ¥å“¦", "åœ¨å‘¢ï½", "é™ªç€ä½ ", "ä¹–å•¦ï½", 
            "è½»è½»æ‰æ‰ï½", "æˆ‘åœ¨å‘¢åˆ«æ€•ï½", "æ²¡å…³ç³»å“¦ï½", "æ…¢æ…¢ä¼šå¥½çš„", "æ·±å‘¼å¸ï½", "ä¸€æ­¥ä¸€æ­¥æ¥", "ä½ å·²ç»å¾ˆåŠªåŠ›äº†å‘¢", "å…è®¸è‡ªå·±éš¾è¿‡å“¦",
            # æ—¥æ–‡
            "ãã‚…ãƒ¼ã£ã¦ã—ã¦ï½", "å¤§ä¸ˆå¤«ã ã‚ˆï½", "ã“ã“ã«ã„ã‚‹ã‚ˆï½", "ã‚ˆã—ã‚ˆã—ï½", "ãˆã‚‰ã„ã­ï½", "ã‚†ã£ãã‚Šã§ã„ã„ã‚ˆ", "ãã°ã«ã„ã‚‹ã‚ˆ", "ä¸€ç·’ã«ã„ã‚‹ã‚ˆ",
            "ã„ã„å­ã ã­ï½", "å„ªã—ãæ’«ã§æ’«ã§ï½", "æ€–ããªã„ã‚ˆã€ç§ãŒã„ã‚‹ï½", "æ°—ã«ã—ãªã„ã§ï½", "ã ã‚“ã ã‚“è‰¯ããªã‚‹ã‚ˆ", "æ·±å‘¼å¸ã—ã¦ï½", "ä¸€æ­©ãšã¤ã­",
            "ã‚‚ã†ã™ã”ãé ‘å¼µã£ã¦ã‚‹ã‚ˆ", "æ‚²ã—ã‚“ã§ã‚‚ã„ã„ã‚“ã ã‚ˆ",
            # è‹±æ–‡
            "hugs~", "it's okay~", "I'm here~", "pat pat~", "good job~", "take your time", "right here with you", "got you~",
            "there there~", "gentle hugs~", "no worries~", "it'll get better", "deep breath~", "one step at a time",
            "you're doing great", "it's okay to feel sad"
        ]

        # ä¸‰è¯­æ·±åº¦å®‰æ…°
        self.comfort_tokens_deep = [
            # ä¸­æ–‡
            "çœŸçš„å¥½å¿ƒç–¼ä½ â€¦â€¦", "æŠ±æŠ±ä½ ï¼Œå¥½å¥½æŠ±ç´§ä¸æ”¾å¼€ï½", "æˆ‘ä¸€ç›´ä¸€ç›´é™ªç€ä½ ï¼Œå¥½ä¸å¥½ï¼Ÿ", "ç°åœ¨å¾ˆéš¾å—ä¹Ÿæ²¡å…³ç³»ï¼Œæˆ‘åœ¨å‘¢",
            "å“­å‡ºæ¥å§ï¼Œæˆ‘å€Ÿä½ è‚©è†€ï½", "ä½ ä¸æ˜¯ä¸€ä¸ªäººå“¦", "æ— è®ºå‘ç”Ÿä»€ä¹ˆï¼Œæˆ‘éƒ½åœ¨è¿™é‡Œ", "æ—¶é—´ä¼šæ…¢æ…¢å†²æ·¡çš„ï¼Œä½†æˆ‘ä¼šä¸€ç›´é™ªä½ èµ°è¿™æ®µè·¯",
            "ä½ å·²ç»å¾ˆåšå¼ºäº†ï¼ŒçœŸçš„", "å…è®¸è‡ªå·±è„†å¼±ä¸€ä¼šå„¿ï¼Œå¥½å—ï¼Ÿ", "æˆ‘ä¼šä¸€ç›´å®ˆç€ä½ ï¼Œç›´åˆ°ä½ é‡æ–°ç¬‘èµ·æ¥ï½",
            # æ—¥æ–‡
            "æœ¬å½“ã«èƒ¸ãŒç—›ã„ã‚ˆâ€¦â€¦", "ãã‚…ãƒ¼ã£ã¦å¼·ãæŠ±ãã—ã‚ã‚‹ã­ï½", "ãšã£ã¨ãšã£ã¨ãã°ã«ã„ã‚‹ã‚ˆã€ã„ã„ã‚ˆã­ï¼Ÿ", "ä»Šã¤ã‚‰ãã¦ã‚‚å¤§ä¸ˆå¤«ã€ç§ãŒã„ã‚‹ã‚ˆ",
            "æ³£ã„ã¦ã‚‚ã„ã„ã‚ˆã€è‚©è²¸ã—ã¦ã‚ã’ã‚‹ï½", "ä¸€äººã˜ã‚ƒãªã„ã‚ˆ", "ä½•ãŒã‚ã£ã¦ã‚‚ã“ã“ã«ã„ã‚‹", "æ™‚é–“ã¯ã‚†ã£ãã‚Šç™’ã—ã¦ãã‚Œã‚‹ã‘ã©ã€ã“ã®é“ã¯ä¸€ç·’ã«æ­©ãã‚ˆ",
            "ã‚‚ã†ååˆ†å¼·ã„ã‚ˆã€æœ¬å½“ã«", "å¼±ããªã£ã¦ã‚‚ã„ã„ã‚ˆã€ã¡ã‚‡ã£ã¨ã ã‘ã§ã„ã„ï¼Ÿ", "ãšã£ã¨è¦‹å®ˆã£ã¦ã‚‹ã€ç¬‘é¡”ãŒæˆ»ã‚‹ã¾ã§ï½",
            # è‹±æ–‡
            "my heart really aches for you...", "big big hugs, holding you tight~", "I'll always be here with you, okay?", "it's okay to hurt right now, I'm here",
            "cry it out, my shoulder's yours~", "you're not alone", "no matter what, I'm right here", "time will soften it, but I'll walk this road with you",
            "you've been so strong already", "it's okay to be vulnerable for a bit, alright?", "I'll stay by your side until your smile comes back~",
            "it's okay to not be okay", "take all the time you need", "I'm here, always", "you're not alone", "lean on me~"
        ]

        # ä¸‰è¯­å®³ç¾å½©è›‹
        self.shy_tokens = [
            # ä¸­æ–‡
            "å‘œâ€¦â€¦", "æœ‰ç‚¹ä¸å¥½æ„æ€å•¦ï½", "è„¸çº¢çº¢çš„ï½", "æ‰­æ", "é‚£ä¸ªâ€¦â€¦", "æˆ‘æˆ‘æˆ‘â€¦â€¦", "å·å·çœ‹ä½ ï½", "å•Šå‘œï½", "ï¼ˆå°å£°ï¼‰", "////",
            "åˆ«è¿™æ ·è¯´å•¦ï½", "äººå®¶ä¼šå®³ç¾çš„ï½",
            # æ—¥æ–‡
            "ã†ã†â€¦â€¦", "ã¡ã‚‡ã£ã¨æ¥ãšã‹ã—ã„ã‚ˆï½", "é¡”çœŸã£èµ¤ï½", "ã‚‚ã˜ã‚‚ã˜", "ãã®â€¦â€¦", "ã‚ã€ã‚ã®â€¦â€¦", "ã“ã£ãã‚Šè¦‹ã¦ã¾ã™ï½", "ã‚ã†ï½", "ï¼ˆå°å£°ï¼‰", "///",
            "ãã‚“ãªã“ã¨è¨€ã‚ãªã„ã§ï½", "æ¥ãšã‹ã—ã„ã‚“ã ã‹ã‚‰ï½",
            # è‹±æ–‡
            "uwu...", "kinda embarrassed~", "blushing hard~", "fidget fidget", "um...", "I-I...", "sneaky peek~", "awuu~", "(whisper)", "///",
            "don't say that~", "you're making me shy~"
        ]

        # æ·±åº¦éš¾è¿‡å…³é”®è¯ï¼ˆå¢åŠ äº†æ—¥æ–‡ï¼‰
        self.deep_sad_keywords = [
            "è¿‡ä¸–", "å»ä¸–", "èµ°äº†", "æ°¸è¿œç¦»å¼€äº†", "äº²äººæ²¡äº†", "çˆ¸çˆ¸å¦ˆå¦ˆ", "çˆ·çˆ·å¥¶å¥¶", "é€ä¸–", "è‘¬ç¤¼", "ä¸§", "æŠ‘éƒ", "å´©æºƒ", "æ´»ä¸ä¸‹å»äº†",
            "died", "passed away", "lost my", "funeral", "grief", "devastated", "broken", "can't go on",
            "æ­»ã‚“ã ", "äº¡ããªã£ãŸ", "æ°¸é ã«", "è‘¬å„€", "å–ª", "ã†ã¤", "å´©å£Š"
        ]

        # å®³ç¾å…³é”®è¯ï¼ˆå¢åŠ äº†æ—¥æ–‡ï¼‰
        self.shy_keywords = [
            "å®³ç¾", "ä¸å¥½æ„æ€", "è„¸çº¢", "å·å·", "æ‰­æ", "ä¸å¥½æ„æ€è¯´", "å‘œâ€¦â€¦", "é‚£ä¸ªâ€¦â€¦",
            "shy", "blush", "embarrassed", "fidget", "um...",
            "æ¥ãšã‹ã—ã„", "ç…§ã‚Œã‚‹", "ã‚‚ã˜ã‚‚ã˜", "ã‚ã®", "ã†ã†"
        ]

        self.sparkle_ids = None
        self.sparkle_boost_mask = None
        self.light_comfort_ids = None
        self.light_comfort_boost_mask = None
        self.deep_comfort_ids = None
        self.deep_comfort_boost_mask = None
        self.shy_ids = None
        self.shy_boost_mask = None
        self.tokenizer = None

    def detect_language(self, tokenizer):
        zh_text = "çš„äº†æ˜¯æˆ‘ä½ åœ¨æœ‰ä¸€å’Œè¿™ä¸ª"
        ja_text = "ã®ã¦ã«ã‚’ã¯ãŒã¨ã§"
        en_text = "the of and to a in that it is was"
        
        zh_len = len(tokenizer.encode(zh_text, add_special_tokens=False))
        ja_len = len(tokenizer.encode(ja_text, add_special_tokens=False))
        en_len = len(tokenizer.encode(en_text, add_special_tokens=False))
        
        scores = {'zh': zh_len, 'ja': ja_len, 'en': en_len}
        min_score = min(scores.values())
        mains = [lang for lang, score in scores.items() if score <= min_score + 2]
        
        if len(mains) > 1 or ('zh' in mains and 'ja' in mains):
            return "mixed"
        return mains[0] if mains else "mixed"

    def detect_mood(self, input_ids):
        if self.tokenizer is None:
            return 0.0
        text = self.tokenizer.decode(input_ids[0], skip_special_tokens=True).lower()
        
        happy_keywords = ["å¼€å¿ƒ", "è€¶", "å¥½æ£’", "å–œæ¬¢", "çˆ±ä½ ", "æ’’å¨‡", "å˜¿å˜¿", "å˜»å˜»", "yay", "happy", "fun", "å…´å¥‹", "å“‡å¡", "å¤ªæ£’å•¦",
                          "å¬‰ã—ã„", "ã‹ã‚ã„ã„", "å¤§å¥½ã", "ã‚ãƒ¼ã„", "ã‚„ã£ãŸãƒ¼"]
        sad_keywords = ["éš¾è¿‡", "ä¼¤å¿ƒ", "å‘œå‘œ", "å“­", "ä¸å¼€å¿ƒ", "ç´¯", "éš¾å—", "çƒ¦", "sad", "tired", "upset", "lonely",
                        "æ‚²ã—ã„", "ã¤ã‚‰ã„", "å¯‚ã—ã„", "æ³£ã"]
        angry_keywords = ["ç”Ÿæ°”", "å“¼", "è®¨åŒ", "çƒ¦", "angry", "mad", "æ€’ã£ã¦ã‚‹", "å«Œã„"]
        
        score = 0.0
        
        if any(k in text for k in happy_keywords): score += 1.8
        if any(k in text for k in self.shy_keywords): score += 0.8
        if any(k in text for k in sad_keywords): score -= 2.0
        if any(k in text for k in angry_keywords): score -= 1.2
        
        if any(k in text for k in self.deep_sad_keywords):
            score -= 5.0
        
        mood = 0.7 * self.memory_mood + 0.3 * score
        self.memory_mood = mood
        return mood

    def set_tokenizer(self, tokenizer):
        self.tokenizer = tokenizer
        lang = self.detect_language(tokenizer)
        
        selected = self.sparkle_tokens_common.copy()
        if lang in ["zh", "mixed"]:
            selected += self.sparkle_tokens_zh
        if lang in ["ja", "mixed"]:
            selected += self.sparkle_tokens_ja
        if lang in ["en", "mixed"]:
            selected += self.sparkle_tokens_en
        
        unique_tokens = list(dict.fromkeys(selected))
        self.sparkle_ids = set()
        for word in unique_tokens:
            ids = tokenizer.encode(word, add_special_tokens=False)
            self.sparkle_ids.update(ids)
        
        unique_light = list(dict.fromkeys(self.comfort_tokens_light))
        self.light_comfort_ids = set()
        for word in unique_light:
            ids = tokenizer.encode(word, add_special_tokens=False)
            self.light_comfort_ids.update(ids)
        
        unique_deep = list(dict.fromkeys(self.comfort_tokens_deep))
        self.deep_comfort_ids = set()
        for word in unique_deep:
            ids = tokenizer.encode(word, add_special_tokens=False)
            self.deep_comfort_ids.update(ids)
        
        unique_shy = list(dict.fromkeys(self.shy_tokens))
        self.shy_ids = set()
        for word in unique_shy:
            ids = tokenizer.encode(word, add_special_tokens=False)
            self.shy_ids.update(ids)
        
        if self.vocab_size:
            self.sparkle_boost_mask = torch.zeros(self.vocab_size, dtype=torch.bool)
            for tid in self.sparkle_ids:
                if tid < self.vocab_size:
                    self.sparkle_boost_mask[tid] = True
                    
            self.light_comfort_boost_mask = torch.zeros(self.vocab_size, dtype=torch.bool)
            for tid in self.light_comfort_ids:
                if tid < self.vocab_size:
                    self.light_comfort_boost_mask[tid] = True
                    
            self.deep_comfort_boost_mask = torch.zeros(self.vocab_size, dtype=torch.bool)
            for tid in self.deep_comfort_ids:
                if tid < self.vocab_size:
                    self.deep_comfort_boost_mask[tid] = True
                    
            self.shy_boost_mask = torch.zeros(self.vocab_size, dtype=torch.bool)
            for tid in self.shy_ids:
                if tid < self.vocab_size:
                    self.shy_boost_mask[tid] = True

    def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor) -> torch.FloatTensor:
        self.step += 1
        logits = scores.clone()
        
        logits = self.repetition_processor(input_ids, logits)
        
        probs = torch.softmax(logits, dim=-1)
        log_probs = torch.log_softmax(logits, dim=-1)
        normalized_ent = -(probs * log_probs).nansum(-1) / math.log(logits.shape[-1])
        ent = normalized_ent.mean()
        
        diff = log_probs + normalized_ent.unsqueeze(-1)
        varent = (probs * diff ** 2).nansum(-1).mean()
        
        if self.prev_ent is None:
            smooth_ent = ent
            smooth_varent = varent
        else:
            smooth_ent = self.alpha * self.prev_ent + (1 - self.alpha) * ent
            smooth_varent = self.alpha * self.prev_varent + (1 - self.alpha) * varent
        self.prev_ent = smooth_ent.detach()
        self.prev_varent = smooth_varent.detach()

        mood_score = self.detect_mood(input_ids)

        if self.dream_mode:
            temp = self.config['dream']['base_temp']
            temp_adjust = self.config['dream']['ent_coeff'] * (smooth_ent - self.config['dream']['target_ent'])
            temp += temp_adjust
            mood_swing = self.config['dream']['mood_swing_amp'] * math.sin(self.step * self.config['dream']['mood_swing_freq'])
            temp += mood_swing
            
            if mood_score > 1.0:
                temp += 0.15
            elif mood_score < -1.0:
                temp -= 0.15
                
            temp = torch.clamp(temp, 0.7, 1.3)
            
            noise_std = self.config['dream']['noise_std_base'] + self.config['dream']['varent_coeff'] * smooth_varent.clamp(0.5, 3.0)
            noise = noise_std * torch.randn_like(logits)
            logits = logits / temp + noise
            
            if smooth_ent < self.config['low_ent_thres'] and self.sparkle_cooldown <= 0:
                base_boost = self.config['dream']['sparkle_boost_base'] + \
                             (self.config['dream']['sparkle_boost_max'] - self.config['dream']['sparkle_boost_base']) * \
                             (self.config['dream']['target_ent'] - smooth_ent) / self.config['dream']['target_ent']
                
                applied = False
                
                if mood_score < -3.0:
                    boost = base_boost * self.config['dream']['deep_comfort_multiplier']
                    mask = self.deep_comfort_boost_mask.to(logits.device)
                    logits[mask] += boost
                    temp = max(temp - 0.3, 0.6)
                    self.sparkle_cooldown = max(1, self.config['dream']['sparkle_cooldown_steps'] // 2)
                    applied = True
                    
                elif mood_score < -0.8:
                    boost = base_boost * self.config['dream']['normal_comfort_multiplier']
                    deep_mask = self.deep_comfort_boost_mask.to(logits.device)
                    light_mask = self.light_comfort_boost_mask.to(logits.device)
                    logits[deep_mask] += boost * 1.2
                    logits[light_mask] += boost * 0.8
                    applied = True
                    
                elif 0.3 < mood_score < 1.8:
                    boost = base_boost * self.config['dream']['shy_multiplier']
                    shy_mask = self.shy_boost_mask.to(logits.device)
                    sparkle_mask = self.sparkle_boost_mask.to(logits.device)
                    logits[shy_mask] += boost
                    logits[sparkle_mask] += boost * 0.6
                    applied = True
                    
                elif mood_score > 1.0:
                    boost = base_boost * self.config['dream']['happy_multiplier']
                    mask = self.sparkle_boost_mask.to(logits.device)
                    logits[mask] += boost
                    applied = True
                
                if not applied:
                    mask = self.sparkle_boost_mask.to(logits.device)
                    logits[mask] += base_boost * self.config['dream']['default_multiplier']
                
                if not applied or mood_score >= -3.0:
                    self.sparkle_cooldown = self.config['dream']['sparkle_cooldown_steps']
            
            if self.sparkle_cooldown > 0:
                self.sparkle_cooldown -= 1
                
            if self.typical_warper:
                logits = self.typical_warper(input_ids, logits)
                
            if self.config['top_p'] < 1.0:
                sorted_logits, sorted_indices = torch.sort(logits, descending=True, dim=-1)
                cumulative_probs = torch.cumsum(torch.softmax(sorted_logits, dim=-1), dim=-1)
                sorted_indices_to_remove = cumulative_probs > self.config['top_p']
                sorted_indices_to_remove[..., 1:] = sorted_indices_to_remove[..., :-1].clone()
                sorted_indices_to_remove[..., 0] = 0
                indices_to_remove = sorted_indices_to_remove.scatter(1, sorted_indices, sorted_indices_to_remove)
                logits[indices_to_remove] = -float('inf')
                
        else:
            temp = self.config['reality']['min_temp'] + self.config['reality']['ent_coeff'] * smooth_ent
            temp = torch.clamp(temp, self.config['reality']['min_temp'], self.config['reality']['max_temp'])
            logits = logits / temp
        
        return logits
